{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/03sarath/google-ai-studio-text-gen/blob/main/Audio_capabilities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Copyright 2025 Psitron Technologies Pvt Ltd\n",
        "\n"
      ],
      "metadata": {
        "id": "TqtG0rzPR6hN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explore audio capabilities with the Gemini API**\n",
        "Gemini can respond to prompts about audio. For example, Gemini can:\n",
        "\n",
        "Describe, summarize, or answer questions about audio content.\n",
        "Provide a transcription of the audio.\n",
        "Provide answers or a transcription about a specific segment of the audio.\n",
        "\n",
        "**Note: You can't generate audio output with the Gemini API.**\n",
        "\n",
        "This guide demonstrates different ways to interact with audio files and audio content using the Gemini API.\n",
        "\n",
        "#Supported audio formats\n",
        "Gemini supports the following audio format MIME types:\n",
        "\n",
        "*   WAV - audio/wav\n",
        "*   MP3 - audio/mp3\n",
        "*   AIFF - audio/aiff\n",
        "*   AAC - audio/aac\n",
        "*   OGG Vorbis - audio/ogg\n",
        "*   FLAC - audio/flac\n",
        "\n",
        "#Technical details about audio\n",
        "Gemini imposes the following rules on audio:\n",
        "\n",
        "*   Gemini represents each second of audio as 25 tokens; for example, one minute of audio is represented as 1,500 tokens.\n",
        "*   Gemini can only infer responses to English-language speech.\n",
        "*   Gemini can \"understand\" non-speech components, such as birdsong or sirens.\n",
        "*   The maximum supported length of audio data in a single prompt is 9.5 hours. Gemini doesn't limit the number of audio files in a single prompt; however, the total combined length of all audio files in a single prompt cannot exceed 9.5 hours.\n",
        "*   Gemini downsamples audio files to a 16 Kbps data resolution.\n",
        "*   If the audio source contains multiple channels, Gemini combines those channels down to a single channel.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6l0K7w5UU2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before you begin: Set up your project and API key\n",
        "**Install the Gemini API library**\n",
        "\n",
        "Using Python 3.9+, install the google-genai package using the following pip command:"
      ],
      "metadata": {
        "id": "S6Ac9aNLUuIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JkqcgohJyqQ",
        "outputId": "4df98249-0e27-41f9-c6af-57868425e25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/164.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m163.8/164.4 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q -U google-genai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get and secure your API key\n",
        "You need an API key to call the Gemini API. If you don't already have one, create a key in Google AI Studio.\n",
        "\n",
        "Using Colab Secrets, you can ensure that your Gemini API key is managed securely and persistently in your Google Colab notebooks."
      ],
      "metadata": {
        "id": "GoCXXGB9c8QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "from google.colab import userdata  # Import for Colab Secrets\n",
        "\n",
        "# Retrieve API key from Colab Secrets\n",
        "try:\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"API key successfully retrieved from Colab Secrets.\")  # Confirmation\n",
        "except KeyError:\n",
        "    raise ValueError(\n",
        "        \"GOOGLE_GENAI_API_KEY not found in Colab Secrets. Please configure your API key in Colab Secrets.\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPW6Roff7YCr",
        "outputId": "da6813be-3906-4b4b-cfd4-c300c092bd02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key successfully retrieved from Colab Secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upload an audio file and generate content\n",
        "You can use the File API to upload an audio file of any size. Always use the File API when the total request size (including the files, text prompt, system instructions, etc.) is larger than 20 MB.\n",
        "\n",
        "Call media.upload to upload a file using the File API. The following code uploads an audio file and then uses the file in a call to models.generateContent.\n",
        "\n",
        "(NOTE:-To use this function, the file must be uploaded in google colab files folder and the uploaded file is available only during that particular runtime in which it was uploaded and gets deleted once that runtime is terminated)"
      ],
      "metadata": {
        "id": "W7E6SgGFeLMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload an audio file and generate content\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=api_key)\n",
        "\n",
        "myfile = client.files.upload(file='/content/mlops_masterclass.mp3')\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model='gemini-2.0-flash',\n",
        "  contents=['Describe this audio clip', myfile]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irPmaPCgoCxh",
        "outputId": "32a16ccb-3ecd-4448-ab51-7ca1699e0d76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This audio clip features Sharath Kumar from Cytron Technologies, advertising a two-day, complete hands-on masterclass on MLOps (Machine Learning Operations), scheduled for March 11th and 12th. The class covers how to build, train, deploy, and monitor machine learning models in a production-ready MLOps pipeline. He emphasizes the live, hands-on nature of the projects, where participants replicate what they see on the instructor's screen. The class includes two real-time projects, focusing on AWS, specifically SageMaker, on the first day to understand machine learning, and then incorporating a complete MLOps pipeline on the second day to deploy in a real-time production environment. This automated ML pipeline includes automated data preparation, retraining, model deployment, and further support through a community group where interview questions, resume preparation, and optimization are discussed. A discount is being offered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get metadata for a file\n",
        "You can verify the API successfully stored the uploaded file and get its metadata by calling files.get."
      ],
      "metadata": {
        "id": "znCJ4rQ1ewls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get metadata for a file\n",
        "myfile = client.files.upload(file='/content/mlops_masterclass.mp3')\n",
        "file_name = myfile.name\n",
        "myfile = client.files.get(name=file_name)\n",
        "print(myfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDWKXN4Kr-ij",
        "outputId": "100fb63c-ded0-4b7c-be1f-f3f382ab0a19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='files/e83d2apyd03v' display_name=None mime_type='audio/mpeg' size_bytes=1246316 create_time=datetime.datetime(2025, 5, 5, 14, 10, 28, 439923, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 5, 7, 14, 10, 28, 404168, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 5, 5, 14, 10, 28, 439923, tzinfo=TzInfo(UTC)) sha256_hash='YTk3ZGQzMTRmNDZlNzgyNGU5ZWEzNDcyY2UxYmZkMzViMmE4N2U1MzU5ZWRjZTM5ODQ1NDhiZDY5ZjE0NzQwYQ==' uri='https://generativelanguage.googleapis.com/v1beta/files/e83d2apyd03v' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Provide the audio file as inline data in the request\n",
        "Instead of uploading an audio file, you can pass audio data in the same call that contains the prompt.\n",
        "\n",
        "(Note the following about providing audio as inline data:-The maximum request size is 20 MB, which includes text prompts, system instructions, and files provided inline. If your file's size will make the total request size exceed 20 MB, then use the File API to upload files for use in requests.\n",
        "If you're using an audio sample multiple times, it is more efficient to use the File API.)\n",
        "\n",
        "Then, pass that downloaded small audio file along with the prompt to Gemini:"
      ],
      "metadata": {
        "id": "9O0BF9rRgi27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Provide the audio file as inline data in the request\n",
        "from google.genai import types\n",
        "\n",
        "with open('/content/mlops_masterclass.mp3', 'rb') as f:\n",
        "    image_bytes = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model='gemini-2.0-flash',\n",
        "  contents=[\n",
        "    'Describe this audio clip',\n",
        "    types.Part.from_bytes(\n",
        "      data=image_bytes,\n",
        "      mime_type='audio/mp3',\n",
        "    )\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFNFAMrktZoe",
        "outputId": "80c48074-2b5d-4b81-bca2-30815b5e83c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The audio clip features Sharad Kumar from Cytron Technologies promoting an upcoming two-day hands-on masterclass on Machine Learning Operations (MLOps). The masterclass, scheduled for March 11th and 12th, will teach participants how to build, train, deploy, and monitor machine learning models in a production-ready MLOps pipeline.  He emphasizes that it's a live, hands-on experience where attendees will replicate projects on their own screens.  The masterclass will include building two real-time projects.  On day one, AWS (especially SageMaker) will be used to understand how to build, train, and deploy machine learning models.  Day two focuses on incorporating the built model into a complete MLOps pipeline and deploying it in a real-time production environment, automating processes like data preparation, retraining, and model deployment. He mentions an affordable price with a 50% discount.  In addition to the masterclass itself, participants will receive access to recordings, slides, and materials, and will become part of a community group for further support and discussion. This might include help with interview questions, resume preparation, and community support.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get a transcript of the audio file\n",
        "To get a transcript, just ask for it in the prompt. For example:"
      ],
      "metadata": {
        "id": "RKOLN5Z0hPLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To get a transcript, just ask for it in the prompt\n",
        "myfile = client.files.upload(file='/content/mlops_masterclass.mp3')\n",
        "prompt = 'Generate a transcript of the speech.'\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model='gemini-2.0-flash',\n",
        "  contents=[prompt, myfile]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3oQNjzouQa2",
        "outputId": "49f0b89f-ae23-4d8d-f3c7-5040f3647689"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello this is sharad kumar from syton technologies I hope you are having a great day thanks for considering us and here is a quick audio message where I am going to provide a quick brief about our upcoming master class on machine learning operations so this is a two days complete hands on master class on mlops which is scheduled for 11th and 12th of march so where you going to learn how to build train deploy and monitor your machine learning models in a production ready mlops pipelines okay so this is a two days master class it's a complete live hands on master class so why do I specify this word live hands on so each and every project the hands ons that we go that we are going to do in this master class it's going to be live so whatever the projects that I will be replicating on my screen so literally you will be replicating on your screen that's how it works so that's the difference okay so in this particular master class we're going to build two real-time projects and on a day one we're going to learn how to build and train and deploy your machine learning models so here we're going to use aws to understand obviously as a platform so here in a day one so we're going to learn how to build train and deploy your machine learning models on aws especially on sagemaker and once we understand how machine learning works on aws so on a day two the same model that we have built we're going to incorporate that with a complete mlops pipeline on and then we're going to deploy it in a real-time production environment just imagine as part of mlops what we are talking about a completely automated ml pipelines what automated data preparation automated retraining automated model deployment and again automated retraining is also part of it so this is the two days complete hands on master class don't miss it so and we have very affordable price that we have for this particular master class we have 50% off the discounts is going on so if you have any questions further if you if you want to know any things further please feel free to contact me so we have already sent you in a curriculum please check out the curriculum for the clear pricing details and again this is not just a master class for the just two days okay so there is a more difference that we are trying to add so once completing this master class yes you will be receiving the access to the recordings the slides everything the materials and again as part of this particular master class we further going to support you every participant who going to be part of this master class they will be part of our community group so we're going to discuss a lot and we're going to learn a lot so let's say it may be sharing the free interview questions it might be helping you in preparing resumes it may be optimizing that and providing a further support as part of a community support so there's a more please check out the curriculum and it's going to be really awesome don't miss it and and if you have any questions feel free to ping me this is sharath until then bye have a great day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get the duration of the audio file\n",
        "To get the duration, just ask for it in the prompt. For example:"
      ],
      "metadata": {
        "id": "ew9FuWEjhmLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt to analyze the duration of the file.\n",
        "myfile = client.files.upload(file='/content/mlops_masterclass.mp3')\n",
        "prompt = \"analyze and tell me how many minutes is the audio file\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model='gemini-2.0-flash',\n",
        "  contents=[prompt, myfile]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LInmE5SvCUR",
        "outputId": "19017ef8-0a35-43cf-e78c-89e478dd1a03"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The audio file is approximately 2 minutes and 18 seconds long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Refer to timestamps in the audio file\n",
        "A prompt can specify timestamps of the form MM:SS to refer to particular sections in an audio file. For example, the following prompt requests a transcript that:\n",
        "\n",
        "Starts from the beginning of the file.\n",
        "Ends at 3 minutes 9 seconds from the beginning of the file."
      ],
      "metadata": {
        "id": "z3uLScKrh-8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt containing timestamps.\n",
        "myfile = client.files.upload(file='/content/mlops_masterclass.mp3')\n",
        "prompt = 'Generate a transcript of the audio from the beginning of the audio file to 1 minutes 9 seconds of the file.'\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model='gemini-2.0-flash',\n",
        "  contents=[prompt, myfile]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Bnw8S4wRyq",
        "outputId": "7ccf195e-bc00-4c4b-b9ef-5c61ba84e191"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, this is Sharath Kumar from Cyton Technologies. I hope you're having a great day. Thanks for considering us and here is a quick audio message where I'm going to provide a quick brief about our upcoming Masterclass on Machine Learning Operations. So, this is a two days complete hands on master class on ML-Ops, which is scheduled for 11th and 12th of March. So, we are going to learn how to build, train, deploy, and monitor your machine learning models in a production ready ML-Ops pipelines. Okay, so this is a two days master class, it's a complete live hands on master class. So, why do I specify this word live hands on. So, each and every projects the hands on that we go that we going to do in this master class it's going to be live. So, whatever the projects that I will be replicating on my screen, so literally you will be replicating on your screen, that's how it works. So, that's a difference. Okay, so in this particular master class, we're going to build two real time projects and a day one, we're going to learn how to build and train and deploy your machine learning models. So, here, we're going to use AWS to understand obviously as a platform. So, here in a day one, so we're going to learn how to build, train, and deploy your machine learning models on AWS, especially on SageMaker. And once we understand how machine learning works on AWS, so on a day two, the same model that we have built, we're going to incorporate that with a complete ML-Ops pipeline and then we're going to deploy it in a real time production environment. Just imagine as part of ML-Ops, what we are talking about a completely automated ML pipelines, what automated data preparation, automated retraining, automated model deployment, and again, automated retraining is also part of it. So, this is the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Count tokens\n",
        "Call the countTokens method to get a count of the number of tokens in the audio file. For example:"
      ],
      "metadata": {
        "id": "7-1C1fxviUpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Call the countTokens method to get a count of the number of tokens in the audio file.\n",
        "myfile = client.files.upload(file='/content/mlops_masterclass.mp3')\n",
        "response = client.models.count_tokens(\n",
        "  model='gemini-2.0-flash',\n",
        "  contents=[myfile]\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpkdtqDqx1xv",
        "outputId": "380ac94a-afcf-4190-d89d-513bce2ce5c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_tokens=4986 cached_content_token_count=None\n"
          ]
        }
      ]
    }
  ]
}